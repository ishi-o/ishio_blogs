---
title: "统计学习: 无监督学习"
date: 2025-11-28
categories: [SE Courses, stat]
tags: [stat, ML]
mathjax: true
---
<!-- placeholder -->
<!-- more -->
# 无监督学习

## 主成分分析

- 主成分分析和主成分回归的第一步很像，使样本矩阵乘上载荷矩阵，载荷矩阵是$p\times M$的矩阵，使共$p$个特征降维为$M$个特征，只不过无法通过交叉验证估计测试误差，也无法选择$M$
- 主成分分析必须**对载荷矩阵进行对标准化**，中心化可选

## 聚类分析

### `K`均值聚类

- `PCA`的本质是降维，保留使得方差大的方向(数据投影到该方向上，能占据较宽的范围)，证明这个方向很接近数据分布的方向，从而实现去噪声
- 而`K`均值聚类则是在`PCA`的基础上做聚类任务，`K`均值聚类事先规定了`K`，而系统聚类通过人工分析得到最终的类别数
- `K`均值聚类希望**类内差异尽可能小**，度量类内差异通常有：
  - 平方欧氏距离：\frac1{n_{k}}\sum_{i,j\in C_k}||\boldsymbol x_{i}\boldsymbol x_j||^2
- `K`均值聚类的步骤：事先定义`K`个类中心，每次迭代使一个样本分类到距离其最近的类中心所代表的类里，然后重新根据类内差异计算类中心，直到所有点所属的类都不再变化

### 系统聚类

- 凝聚法(自下而上)：每次迭代选出两类合并为一类(初始每个样本独自为一类)
- 选择合并双方的评判方法有：
  - 最长距离法：选取最大差异度最小的两类
  - 最短距离法：选取最小差异度最小的两类
  - 重心法：选取两类的重心(所有样本点各个特征的平均值为重心的各个特征值)距离最小的两类(会发生颠倒现象)
  - 类平均法：选取平均差异度最小的两类
- 差异度的评判方法：
  - 欧氏距离
  - 基于相关性的距离
