---
title: "统计学习: 非线性模型"
date: 2025-11-24
categories: [SE Courses, stat]
tags: [stat]
mathjax: true
---
<!-- placeholder -->
<!-- more -->
# 非线性模型

## 基函数

### 多项式回归

- 多项式回归通过添加变量的幂来实现非线性的拟合

### 阶梯函数

- 阶梯函数通过将预测变量的取值划分为$K$个区间，来得到$K+1$个新的定性的变量

### 基函数推广

- 基函数本质是针对一个预测变量$X$做许多变换，来增加模型的复杂度，其基本形式是：

  $$
  y=\beta_0+\beta_1b_1(X)+\dots+\beta_kb_k(X)+\epsilon
  $$

- 多项式回归和阶梯函数都是基函数的特例

## 回归样条

- 回归样条在分段多项式回归的基础上添加限制条件，使不同区间在分段点上连接，称为`spline`(样条)
- `d`阶样条是`d`阶多项式在每个分段点的零阶到`d-1`阶的导数都是连续的
- 样条基函数：通过将`d`阶多项式改写为$y=\beta_0+\beta_1b_1(x)+\dots+\beta_kb_k(x)+\epsilon$的基函数的形式，能减小使其`k`阶导数连续的难度
- 线性样条：
- 三次样条：有`K`个节点的三次样条的自由度为`K+4`
- 自然样条：有`K`个节点的自然样条的自由度为`K`
- 结点选择：通过交叉验证选择

## 光滑样条

- 光滑样条不同于回归样条，通过在最小二乘损失函数$RSS$的基础上添加光滑惩罚项(波动性惩罚)$\begin{align}\lambda\int g''(t)^2\mathrm dt\end{align}$
- 这个对二阶导求和的惩罚项要求模型在节点处限制其粗糙程度，样条越光滑二阶导的积分越小
- 最终结果是自然三次样条的收缩版本，$\lambda$是收缩程度，$\lambda$同样通过交叉验证选择
- 其自由度随$\lambda$增大从$n$降低到$2$

## 局部回归

- 局部回归在训练时只使用一个点附近的数据来拟合

## 广义可加模型

- 广义可加模型在多项式回归函数的基础上，将$\beta_jx_j$改为$f_j(x_j)$非线性函数(例如上面的阶梯函数和样条函数)，称为可加模型
