---
title: "统计学习: 树型模型"
date: 2025-11-25
categories: [SE Courses, stat]
tags: [stat, ML]
mathjax: true
---
<!-- placeholder -->
<!-- more -->
# 树模型

## 决策树

### 树方法的特点

- 解释性强，方法简单
- 准确性不如之前介绍的方法

### 回归树

- 回归树的损失函数是将$RSS$划分为多个区域$R_j$，形式为：

  $$
  RSS=\sum_{j=1}^J\sum_{i\in R_j}(y_i-\hat y_{R_j})^2
  $$

- 建树方法：递归二叉分裂：
  - 自上而下：从顶端开始，选择预测变量和分割点(每一个预测变量都可以分段，所有分割点就是所有变量的分割点的集合)
  - 贪婪：选择能使树的$RSS$最小的那个分割点$s$
- 剪枝：递归二叉分裂的过拟合较为严重，需要剪枝防止预测结果进一步分裂
  - 代价复杂性剪枝(最弱联系剪枝)：对$RSS$添加惩罚项：

    $$
    RSS=\sum_{j=1}^J\sum_{i\in R_j}(y_i-\hat y_{R_j})^2+\alpha|T|
    $$  

    其中$\alpha$对应一棵子树，是非负的超参数，$|T|$为该子树的叶子节点数，$\alpha$同样通过交叉验证选择

    即叶子结点数越多，惩罚越大

### 分类树

- 分类树和回归树类似，只不过损失函数需要变化

- 效果较差的分类错误率：

  $$
  E=1-\max_k(\hat p_{mk})
  $$

  $\hat p_{mk}$是在第$m$个区域第$k$类所占比例，即所有非最常见类的预测比例
- 基尼系数：

  $$
  G=\sum_{k=1}^K\hat p_{mk}(1-\hat p_{mk})
  $$

- 交叉熵：

  $$
  D=-\sum_{k=1}^K\hat p_{mk}\log \hat p_{mk}
  $$

## 装袋法

- 装袋法又称自助法聚集，学习自助法可以知道，通过有放回重复采样可以平均方差，使预测结果的**方差减小**
- 装袋法通过生成$B$棵树，分别进行预测，求平均得到最终的预测结果
- 针对分类树，采用多数投票的方法，取最多投票的分类作为最终的预测结果
- 由自助法，每个自助样本包含原始样本大约$\frac23$的样本点，那么一颗自助树的袋外样本就有$\frac13$，那么不使用这$\frac13$袋外样本作为训练集的自助树有$\frac B3$棵，通过这$\frac B3$个袋外预测值就能估计测试误差了
- 它的估计过程和自助法估计不同，自助法针对每个模型计算袋外样本的测试误差，然后平均(共`模型数`个)，装袋法针对每个袋外样本先算测试误差，然后平均(共`袋外样本数`个)

## 随机森林

- 随机森林本质是变量数更少的装袋法，在每个分裂点都选出$m\le p$个变量来训练，通常$m$取$\sqrt p$

## 提升法

- 提升法适用于多个回归方法，针对回归树，它先训练多个弱学习器，不过是顺序训练的，后面的学习器会采用前面学习器的残差作为$y$
- 提升法的目标是降低偏差
